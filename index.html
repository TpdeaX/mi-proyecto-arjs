<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <script src="https://aframe.io/releases/1.2.0/aframe.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@ar-js-org/ar.js/aframe/build/aframe-ar-nft.min.js"></script>
    <style>
      #switchCamera {
        position: fixed;
        bottom: 20px;
        right: 20px;
        z-index: 9999;
        padding: 10px;
        background: rgba(255, 255, 255, 0.8);
        border: 1px solid #000;
        border-radius: 5px;
        cursor: pointer;
      }
    </style>
  </head>
  <body>
    <button id="switchCamera" onclick="toggleCamera()">Cambiar C치mara</button>

    <script>
      let currentScene = null;
      let currentStream = null;

      async function initializeARScene(facingMode) {
  // Clean up previous scene and stream
  if (currentScene) {
    currentScene.parentNode.removeChild(currentScene);
  }
  if (currentStream) {
    currentStream.getTracks().forEach(track => track.stop());
  }

  // Create new scene
  const scene = document.createElement('a-scene');
  scene.setAttribute('embedded', '');
  scene.setAttribute('arjs', `
    sourceType: webcam;
    debugUIEnabled: false;
  `);

  // Add camera and assets
  const camera = document.createElement('a-camera');
  camera.setAttribute('gps-camera', '');
  camera.setAttribute('rotation-reader', '');

  const assets = document.createElement('a-assets');
  assets.setAttribute('timeout', '10000');

  scene.appendChild(assets);
  scene.appendChild(camera);
  document.body.appendChild(scene);
  currentScene = scene;

  // Access camera stream
  try {
    currentStream = await navigator.mediaDevices.getUserMedia({
      video: {
        facingMode: { exact: facingMode },
        width: { ideal: 1280 },
        height: { ideal: 720 }
      }
    });

    // Update AR.js video source
    const arjsSys = scene.systems['arjs'];
    arjsSys._arSource = new THREEx.ArToolkitSource({
      sourceType: 'webcam',
      sourceUrl: currentStream
    });

    arjsSys._arSource.init(() => {
      arjsSys._arSource.onResize();
      arjsSys._arContext.init(() => {
        scene.emit('arjs-video-loaded', {
          component: arjsSys._arSource
        });
      });
    });

    // Load models
    loadModels();

    // Log camera settings
    const track = currentStream.getVideoTracks()[0];
    console.log('Configuraci칩n actual:', {
      facingMode: track.getSettings().facingMode,
      deviceId: track.getSettings().deviceId
    });
  } catch (error) {
    console.error('Error al acceder a la c치mara:', error);
  }
}

      
      async function loadModels() {
  try {
    const response = await fetch("models.json");
    const models = await response.json();
    const assets = currentScene.querySelector('a-assets');
    models.forEach((item) => {
      const asset = document.createElement("a-asset-item");
      asset.setAttribute("id", item.id);
      asset.setAttribute("src", item.src);
      assets.appendChild(asset);

      const entity = document.createElement("a-entity");
      entity.setAttribute("gltf-model", `#${item.id}`);
      entity.setAttribute("gps-entity-place", `latitude: ${item.latitude}; longitude: ${item.longitude};`);
      entity.setAttribute("scale", item.scale);
      currentScene.appendChild(entity);
    });
  } catch (error) {
    console.error("Error al cargar modelos:", error);
  }
}

      function toggleCamera() {
  const urlParams = new URLSearchParams(window.location.search);
  const newMode = urlParams.get('camera') === 'front' ? 'environment' : 'user';
  urlParams.set('camera', newMode === 'user' ? 'front' : '');
  window.location.search = urlParams.toString();
}

      // Inicializaci칩n inicial
      document.addEventListener('DOMContentLoaded', () => {
  const urlParams = new URLSearchParams(window.location.search);
  const cameraMode = urlParams.get('camera') === 'front' ? 'user' : 'environment';
  initializeARScene(cameraMode);
});
    </script>
  </body>
</html>
